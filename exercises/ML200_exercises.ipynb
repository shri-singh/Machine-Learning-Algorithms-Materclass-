{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML200 Exercises: Linear Regression\n",
    "\n",
    "These exercises cover linear regression fundamentals: simple and multiple regression,\n",
    "assumption checking, regularization (Ridge, Lasso, ElasticNet), and pipeline construction.\n",
    "\n",
    "**Difficulty increases with each exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Setup: Run this cell first\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Ridge, Lasso, ElasticNet, LassoCV\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_california_housing, make_regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1: Simple Linear Regression on California Housing\n",
    "\n",
    "**Goal:** Fit a linear regression using 2 features from the California Housing\n",
    "dataset, report R-squared, and create an actual vs. predicted scatter plot.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load California Housing and select `MedInc` and `AveRooms` as features.\n",
    "2. Perform an 80/20 split (`random_state=42`).\n",
    "3. Fit a `LinearRegression` model.\n",
    "4. Compute R-squared on the test set.\n",
    "5. Create a scatter plot of actual vs. predicted values with a diagonal reference line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 - Starter Code\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "# TODO 1: Select MedInc and AveRooms as features\n",
    "# X = df[['MedInc', 'AveRooms']]\n",
    "# y = df['MedHouseVal']\n",
    "\n",
    "# TODO 2: 80/20 split\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# TODO 3: Fit LinearRegression\n",
    "# model = LinearRegression()\n",
    "# model.fit(...)\n",
    "\n",
    "# TODO 4: Predict and compute R2\n",
    "# y_pred = model.predict(X_test)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# TODO 5: Plot actual vs predicted\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.title('Actual vs Predicted House Values')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "\n",
    "# 1. Select features\n",
    "X = df[['MedInc', 'AveRooms']]\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# 2. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Fit\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "print(f\"Coefficients: {dict(zip(X.columns, model.coef_))}\")\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "\n",
    "# 5. Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted House Values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2: Check Linear Regression Assumptions\n",
    "\n",
    "**Goal:** After fitting a linear regression, create diagnostic plots to check\n",
    "the assumptions of linearity and normality of residuals.\n",
    "\n",
    "**Tasks:**\n",
    "1. Fit a linear regression on the California Housing dataset (all features).\n",
    "2. Compute residuals (`y_test - y_pred`).\n",
    "3. Create a residual plot (predicted values vs. residuals).\n",
    "4. Create a Q-Q plot of the residuals using `scipy.stats.probplot`.\n",
    "5. Interpret the plots in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - Starter Code\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# TODO 1: Compute residuals\n",
    "# residuals = ...\n",
    "\n",
    "# TODO 2: Create residual plot (predicted vs residuals)\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# axes[0].scatter(y_pred, residuals, alpha=0.3)\n",
    "# axes[0].axhline(y=0, color='r', linestyle='--')\n",
    "# axes[0].set_xlabel('Predicted Values')\n",
    "# axes[0].set_ylabel('Residuals')\n",
    "# axes[0].set_title('Residual Plot')\n",
    "\n",
    "# TODO 3: Create Q-Q plot\n",
    "# stats.probplot(residuals, dist='norm', plot=axes[1])\n",
    "# axes[1].set_title('Q-Q Plot of Residuals')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# TODO 4: Interpretation (write in a comment)\n",
    "# Your interpretation: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 1. Compute residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# 2 & 3. Diagnostic plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residual plot\n",
    "axes[0].scatter(y_pred, residuals, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Predicted Values')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title('Residual Plot')\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuals, dist='norm', plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Interpretation:\n",
    "# - The residual plot shows a pattern (non-random scatter), suggesting\n",
    "#   the linear model does not fully capture the relationship.\n",
    "# - The Q-Q plot shows deviations from the diagonal in the tails,\n",
    "#   indicating the residuals are not perfectly normally distributed.\n",
    "# - This suggests a non-linear model or feature transformations may help.\n",
    "print(\"Residual statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.4f} (should be ~0)\")\n",
    "print(f\"  Std:  {residuals.std():.4f}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3: Ridge vs. Lasso vs. ElasticNet\n",
    "\n",
    "**Goal:** Compare Ridge, Lasso, and ElasticNet regression using 5-fold\n",
    "cross-validation on a synthetic dataset with 20 features (only 5 informative).\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate a synthetic regression dataset with `make_regression`.\n",
    "2. Train Ridge, Lasso, and ElasticNet models (all with `alpha=1.0`).\n",
    "3. Evaluate each with 5-fold CV using negative MSE.\n",
    "4. Print the results in a comparison table.\n",
    "5. Discuss which model performs best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 - Starter Code\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Generate synthetic data: 20 features, only 5 are informative\n",
    "X, y = make_regression(\n",
    "    n_samples=500, n_features=20, n_informative=5,\n",
    "    noise=10, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# TODO 1: Create models with alpha=1.0\n",
    "# ridge = Ridge(alpha=1.0, random_state=42)\n",
    "# lasso = Lasso(alpha=1.0, random_state=42)\n",
    "# elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "\n",
    "# TODO 2: Evaluate each with 5-fold CV\n",
    "# scoring = 'neg_mean_squared_error'\n",
    "# ridge_scores = cross_val_score(ridge, X, y, cv=5, scoring=scoring)\n",
    "# lasso_scores = ...\n",
    "# elasticnet_scores = ...\n",
    "\n",
    "# TODO 3: Print comparison (convert neg MSE to positive)\n",
    "# for name, scores in [('Ridge', ridge_scores), ('Lasso', lasso_scores), ('ElasticNet', elasticnet_scores)]:\n",
    "#     mse = -scores.mean()\n",
    "#     std = scores.std()\n",
    "#     print(f\"{name:12s} MSE: {mse:.2f} +/- {std:.2f}\")\n",
    "\n",
    "# TODO 4: Fit all models and compare number of zero coefficients\n",
    "# (Hint: Lasso should zero out uninformative features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = make_regression(\n",
    "    n_samples=500, n_features=20, n_informative=5,\n",
    "    noise=10, random_state=42\n",
    ")\n",
    "\n",
    "# 1. Create models\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=1.0, random_state=42)\n",
    "elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n",
    "\n",
    "# 2. Evaluate\n",
    "scoring = 'neg_mean_squared_error'\n",
    "ridge_scores = cross_val_score(ridge, X, y, cv=5, scoring=scoring)\n",
    "lasso_scores = cross_val_score(lasso, X, y, cv=5, scoring=scoring)\n",
    "elasticnet_scores = cross_val_score(elasticnet, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# 3. Print comparison\n",
    "print(\"Model Comparison (5-fold CV):\")\n",
    "print(\"-\" * 40)\n",
    "for name, scores in [('Ridge', ridge_scores), ('Lasso', lasso_scores), ('ElasticNet', elasticnet_scores)]:\n",
    "    mse = -scores.mean()\n",
    "    std = scores.std()\n",
    "    print(f\"{name:12s} MSE: {mse:8.2f} +/- {std:.2f}\")\n",
    "\n",
    "# 4. Compare coefficients\n",
    "print(\"\\nNumber of zero coefficients:\")\n",
    "for name, model in [('Ridge', ridge), ('Lasso', lasso), ('ElasticNet', elasticnet)]:\n",
    "    model.fit(X, y)\n",
    "    n_zeros = np.sum(np.abs(model.coef_) < 1e-10)\n",
    "    print(f\"{name:12s}: {n_zeros} / {len(model.coef_)} features zeroed out\")\n",
    "\n",
    "# Lasso tends to zero out uninformative features (feature selection),\n",
    "# ElasticNet zeros out some too, Ridge keeps all features non-zero.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4: LassoCV for Optimal Alpha\n",
    "\n",
    "**Goal:** Use `LassoCV` to automatically find the best regularization strength\n",
    "and identify which features get zeroed out.\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate a synthetic dataset with `make_regression` (20 features, 5 informative).\n",
    "2. Fit `LassoCV` with 5-fold CV.\n",
    "3. Report the optimal alpha.\n",
    "4. List which features are zeroed out (coefficient = 0).\n",
    "5. Plot the coefficient values as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 - Starter Code\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y, true_coefs = make_regression(\n",
    "    n_samples=500, n_features=20, n_informative=5,\n",
    "    noise=10, coef=True, random_state=42\n",
    ")\n",
    "feature_names = [f'feature_{i}' for i in range(20)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TODO 1: Fit LassoCV\n",
    "# lasso_cv = LassoCV(cv=5, random_state=42)\n",
    "# lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# TODO 2: Report optimal alpha\n",
    "# print(f\"Optimal alpha: {lasso_cv.alpha_:.4f}\")\n",
    "\n",
    "# TODO 3: Report R2 on test set\n",
    "# r2 = lasso_cv.score(X_test, y_test)\n",
    "# print(f\"Test R2: {r2:.4f}\")\n",
    "\n",
    "# TODO 4: Identify zeroed-out features\n",
    "# for name, coef in zip(feature_names, lasso_cv.coef_):\n",
    "#     status = 'ZERO' if abs(coef) < 1e-10 else f'{coef:.4f}'\n",
    "#     print(f\"{name}: {status}\")\n",
    "\n",
    "# TODO 5: Bar chart of coefficients\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.bar(feature_names, lasso_cv.coef_)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel('Coefficient Value')\n",
    "# plt.title('Lasso Coefficients (LassoCV)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y, true_coefs = make_regression(\n",
    "    n_samples=500, n_features=20, n_informative=5,\n",
    "    noise=10, coef=True, random_state=42\n",
    ")\n",
    "feature_names = [f'feature_{i}' for i in range(20)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 1. Fit LassoCV\n",
    "lasso_cv = LassoCV(cv=5, random_state=42)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# 2. Optimal alpha\n",
    "print(f\"Optimal alpha: {lasso_cv.alpha_:.4f}\")\n",
    "\n",
    "# 3. Test R2\n",
    "r2 = lasso_cv.score(X_test, y_test)\n",
    "print(f\"Test R2: {r2:.4f}\")\n",
    "\n",
    "# 4. Identify zeroed-out features\n",
    "print(\"\\nFeature coefficients:\")\n",
    "n_zeros = 0\n",
    "for name, coef, true_c in zip(feature_names, lasso_cv.coef_, true_coefs):\n",
    "    status = 'ZERO' if abs(coef) < 1e-10 else f'{coef:.4f}'\n",
    "    true_status = 'ZERO' if abs(true_c) < 1e-10 else f'{true_c:.4f}'\n",
    "    print(f\"{name}: Lasso={status:>10s}  True={true_status:>10s}\")\n",
    "    if abs(coef) < 1e-10:\n",
    "        n_zeros += 1\n",
    "print(f\"\\nFeatures zeroed out: {n_zeros} / 20\")\n",
    "\n",
    "# 5. Bar chart\n",
    "plt.figure(figsize=(12, 5))\n",
    "x_pos = np.arange(len(feature_names))\n",
    "plt.bar(x_pos - 0.2, lasso_cv.coef_, 0.4, label='Lasso', alpha=0.8)\n",
    "plt.bar(x_pos + 0.2, true_coefs, 0.4, label='True', alpha=0.8)\n",
    "plt.xticks(x_pos, feature_names, rotation=45)\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Lasso vs True Coefficients')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5: Full Pipeline - StandardScaler + Ridge\n",
    "\n",
    "**Goal:** Build a complete pipeline that scales features and applies Ridge\n",
    "regression, then evaluate with cross-validation.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the California Housing dataset.\n",
    "2. Create a `Pipeline` with `StandardScaler` and `Ridge(alpha=1.0)`.\n",
    "3. Evaluate with 5-fold cross-validation (R-squared scoring).\n",
    "4. Compare the pipeline results against an unscaled Ridge model.\n",
    "5. Print both results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 - Starter Code\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# TODO 1: Create pipeline (StandardScaler -> Ridge)\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('ridge', Ridge(alpha=1.0))\n",
    "# ])\n",
    "\n",
    "# TODO 2: Evaluate pipeline with 5-fold CV (scoring='r2')\n",
    "# pipeline_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# TODO 3: Evaluate unscaled Ridge for comparison\n",
    "# ridge_only = Ridge(alpha=1.0)\n",
    "# unscaled_scores = cross_val_score(ridge_only, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# TODO 4: Print comparison\n",
    "# print(f\"Pipeline (Scaled + Ridge) R2: {pipeline_scores.mean():.4f} +/- {pipeline_scores.std():.4f}\")\n",
    "# print(f\"Unscaled Ridge          R2: {unscaled_scores.mean():.4f} +/- {unscaled_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# 1. Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "# 2. Evaluate pipeline\n",
    "pipeline_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# 3. Evaluate unscaled Ridge\n",
    "ridge_only = Ridge(alpha=1.0)\n",
    "unscaled_scores = cross_val_score(ridge_only, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# 4. Print comparison\n",
    "print(\"Pipeline vs Unscaled Ridge:\")\n",
    "print(f\"Pipeline (Scaled + Ridge) R2: {pipeline_scores.mean():.4f} +/- {pipeline_scores.std():.4f}\")\n",
    "print(f\"Unscaled Ridge           R2: {unscaled_scores.mean():.4f} +/- {unscaled_scores.std():.4f}\")\n",
    "print(f\"\\nScaling {'improved' if pipeline_scores.mean() > unscaled_scores.mean() else 'did not improve'} performance.\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}