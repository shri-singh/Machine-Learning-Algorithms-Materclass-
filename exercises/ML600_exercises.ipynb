{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML600 Exercises: Optimization, Regularization & Model Selection\n",
    "\n",
    "These exercises cover gradient descent from scratch, bias-variance tradeoff visualization,\n",
    "hyperparameter tuning with GridSearchCV, recursive feature elimination, and an end-to-end\n",
    "mini-project.\n",
    "\n",
    "**Difficulty increases with each exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Setup: Run this cell first\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, accuracy_score, classification_report\n",
    ")\n",
    "from sklearn.datasets import (\n",
    "    load_diabetes, load_breast_cancer, make_classification\n",
    ")\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1: Gradient Descent from Scratch\n",
    "\n",
    "**Goal:** Implement gradient descent for simple 1D linear regression\n",
    "(y = w*x + b) from scratch and plot the cost function over iterations.\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate synthetic 1D data: y = 3*x + 5 + noise.\n",
    "2. Implement the gradient descent update rules for w and b.\n",
    "3. Run gradient descent for 200 iterations with learning_rate = 0.01.\n",
    "4. Track the MSE cost at each iteration.\n",
    "5. Plot cost vs. iterations and the final regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 - Starter Code\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data: y = 3x + 5 + noise\n",
    "n_samples = 100\n",
    "X = 2 * np.random.rand(n_samples)  # values between 0 and 2\n",
    "y_true = 3 * X + 5 + np.random.randn(n_samples) * 0.5\n",
    "\n",
    "# Initialize parameters\n",
    "w = 0.0   # weight (slope)\n",
    "b = 0.0   # bias (intercept)\n",
    "learning_rate = 0.01\n",
    "n_iterations = 200\n",
    "\n",
    "# TODO 1: Implement gradient descent\n",
    "# costs = []\n",
    "# for i in range(n_iterations):\n",
    "#     # Forward pass: predictions\n",
    "#     y_pred = w * X + b\n",
    "#\n",
    "#     # Compute cost (MSE)\n",
    "#     cost = np.mean((y_pred - y_true) ** 2)\n",
    "#     costs.append(cost)\n",
    "#\n",
    "#     # Compute gradients\n",
    "#     dw = (2 / n_samples) * np.sum((y_pred - y_true) * X)\n",
    "#     db = (2 / n_samples) * np.sum(y_pred - y_true)\n",
    "#\n",
    "#     # Update parameters\n",
    "#     w = w - learning_rate * dw\n",
    "#     b = b - learning_rate * db\n",
    "#\n",
    "#     if (i + 1) % 50 == 0:\n",
    "#         print(f\"Iteration {i+1:3d}: cost={cost:.4f}, w={w:.4f}, b={b:.4f}\")\n",
    "\n",
    "# TODO 2: Print final parameters\n",
    "# print(f\"\\nFinal: w={w:.4f} (true=3.0), b={b:.4f} (true=5.0)\")\n",
    "\n",
    "# TODO 3: Plot cost vs iterations\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# axes[0].plot(costs)\n",
    "# axes[0].set_xlabel('Iteration')\n",
    "# axes[0].set_ylabel('MSE Cost')\n",
    "# axes[0].set_title('Cost vs Iterations')\n",
    "\n",
    "# TODO 4: Plot data with final regression line\n",
    "# axes[1].scatter(X, y_true, alpha=0.5, label='Data')\n",
    "# X_line = np.linspace(0, 2, 100)\n",
    "# axes[1].plot(X_line, w * X_line + b, 'r-', label=f'y = {w:.2f}x + {b:.2f}', lw=2)\n",
    "# axes[1].set_xlabel('X')\n",
    "# axes[1].set_ylabel('y')\n",
    "# axes[1].set_title('Linear Regression (Gradient Descent)')\n",
    "# axes[1].legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "n_samples = 100\n",
    "X = 2 * np.random.rand(n_samples)\n",
    "y_true = 3 * X + 5 + np.random.randn(n_samples) * 0.5\n",
    "\n",
    "# Initialize\n",
    "w = 0.0\n",
    "b = 0.0\n",
    "learning_rate = 0.01\n",
    "n_iterations = 200\n",
    "\n",
    "# 1. Gradient descent\n",
    "costs = []\n",
    "for i in range(n_iterations):\n",
    "    y_pred = w * X + b\n",
    "    cost = np.mean((y_pred - y_true) ** 2)\n",
    "    costs.append(cost)\n",
    "\n",
    "    dw = (2 / n_samples) * np.sum((y_pred - y_true) * X)\n",
    "    db = (2 / n_samples) * np.sum(y_pred - y_true)\n",
    "\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"Iteration {i+1:3d}: cost={cost:.4f}, w={w:.4f}, b={b:.4f}\")\n",
    "\n",
    "# 2. Final parameters\n",
    "print(f\"\\nFinal: w={w:.4f} (true=3.0), b={b:.4f} (true=5.0)\")\n",
    "\n",
    "# 3 & 4. Plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(costs)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('MSE Cost')\n",
    "axes[0].set_title('Cost vs Iterations')\n",
    "\n",
    "axes[1].scatter(X, y_true, alpha=0.5, label='Data')\n",
    "X_line = np.linspace(0, 2, 100)\n",
    "axes[1].plot(X_line, w * X_line + b, 'r-', label=f'y = {w:.2f}x + {b:.2f}', lw=2)\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('y')\n",
    "axes[1].set_title('Linear Regression (Gradient Descent)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2: Bias-Variance Tradeoff Visualization\n",
    "\n",
    "**Goal:** Fit polynomials of increasing degree to a noisy dataset and visualize\n",
    "the bias-variance tradeoff by plotting train and test error.\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate synthetic data: y = sin(2*pi*x) + noise.\n",
    "2. Split into train/test.\n",
    "3. Fit polynomial regression of degrees 1, 3, 5, 9, 15.\n",
    "4. Compute train and test MSE for each degree.\n",
    "5. Plot train/test error vs. polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - Starter Code\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate noisy sine data\n",
    "n_samples = 100\n",
    "X = np.sort(np.random.uniform(0, 1, n_samples)).reshape(-1, 1)\n",
    "y = np.sin(2 * np.pi * X).ravel() + np.random.randn(n_samples) * 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "degrees = [1, 3, 5, 9, 15]\n",
    "\n",
    "# TODO 1: For each degree, fit polynomial regression and compute train/test MSE\n",
    "# train_errors = []\n",
    "# test_errors = []\n",
    "# for degree in degrees:\n",
    "#     poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "#     X_train_poly = poly.fit_transform(X_train)\n",
    "#     X_test_poly = poly.transform(X_test)\n",
    "#\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train_poly, y_train)\n",
    "#\n",
    "#     train_mse = mean_squared_error(y_train, model.predict(X_train_poly))\n",
    "#     test_mse = mean_squared_error(y_test, model.predict(X_test_poly))\n",
    "#     train_errors.append(train_mse)\n",
    "#     test_errors.append(test_mse)\n",
    "#     print(f\"Degree {degree:2d}: Train MSE = {train_mse:.4f}, Test MSE = {test_mse:.4f}\")\n",
    "\n",
    "# TODO 2: Plot train vs test error\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(degrees, train_errors, 'o-', label='Train MSE')\n",
    "# plt.plot(degrees, test_errors, 's-', label='Test MSE')\n",
    "# plt.xlabel('Polynomial Degree')\n",
    "# plt.ylabel('Mean Squared Error')\n",
    "# plt.title('Bias-Variance Tradeoff')\n",
    "# plt.legend()\n",
    "# plt.xticks(degrees)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# TODO 3: Plot the fitted curves for each degree\n",
    "# fig, axes = plt.subplots(1, len(degrees), figsize=(20, 4))\n",
    "# X_plot = np.linspace(0, 1, 200).reshape(-1, 1)\n",
    "# for idx, degree in enumerate(degrees):\n",
    "#     poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "#     X_train_poly = poly.fit_transform(X_train)\n",
    "#     X_plot_poly = poly.transform(X_plot)\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train_poly, y_train)\n",
    "#     y_plot = model.predict(X_plot_poly)\n",
    "#\n",
    "#     axes[idx].scatter(X_train, y_train, s=10, alpha=0.5)\n",
    "#     axes[idx].plot(X_plot, y_plot, 'r-', lw=2)\n",
    "#     axes[idx].plot(X_plot, np.sin(2 * np.pi * X_plot), 'g--', lw=1, alpha=0.5)\n",
    "#     axes[idx].set_title(f'Degree {degree}')\n",
    "#     axes[idx].set_ylim(-2, 2)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 100\n",
    "X = np.sort(np.random.uniform(0, 1, n_samples)).reshape(-1, 1)\n",
    "y = np.sin(2 * np.pi * X).ravel() + np.random.randn(n_samples) * 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "degrees = [1, 3, 5, 9, 15]\n",
    "\n",
    "# 1. Fit and evaluate\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, model.predict(X_train_poly))\n",
    "    test_mse = mean_squared_error(y_test, model.predict(X_test_poly))\n",
    "    train_errors.append(train_mse)\n",
    "    test_errors.append(test_mse)\n",
    "    print(f\"Degree {degree:2d}: Train MSE = {train_mse:.4f}, Test MSE = {test_mse:.4f}\")\n",
    "\n",
    "# 2. Error plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(degrees, train_errors, 'o-', label='Train MSE')\n",
    "plt.plot(degrees, test_errors, 's-', label='Test MSE')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Bias-Variance Tradeoff')\n",
    "plt.legend()\n",
    "plt.xticks(degrees)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Fitted curves\n",
    "fig, axes = plt.subplots(1, len(degrees), figsize=(20, 4))\n",
    "X_plot = np.linspace(0, 1, 200).reshape(-1, 1)\n",
    "for idx, degree in enumerate(degrees):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_plot_poly = poly.transform(X_plot)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    y_plot = model.predict(X_plot_poly)\n",
    "\n",
    "    axes[idx].scatter(X_train, y_train, s=10, alpha=0.5)\n",
    "    axes[idx].plot(X_plot, y_plot, 'r-', lw=2)\n",
    "    axes[idx].plot(X_plot, np.sin(2 * np.pi * X_plot), 'g--', lw=1, alpha=0.5)\n",
    "    axes[idx].set_title(f'Degree {degree}')\n",
    "    axes[idx].set_ylim(-2, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observations:\n",
    "# - Degree 1: High bias (underfitting) -- cannot capture the sine wave.\n",
    "# - Degree 3-5: Good fit -- captures the pattern without overfitting.\n",
    "# - Degree 9-15: High variance (overfitting) -- fits noise in training data.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3: GridSearchCV for Random Forest Tuning\n",
    "\n",
    "**Goal:** Use `GridSearchCV` to find the best hyperparameters for a Random Forest\n",
    "classifier.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the breast cancer dataset.\n",
    "2. Define a parameter grid for `n_estimators` and `max_depth`.\n",
    "3. Run `GridSearchCV` with 5-fold cross-validation.\n",
    "4. Report the best parameters and best score.\n",
    "5. Evaluate the best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 - Starter Code\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TODO 1: Define parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [3, 5, 10, None]\n",
    "# }\n",
    "\n",
    "# TODO 2: Create GridSearchCV\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# grid_search = GridSearchCV(\n",
    "#     rf, param_grid, cv=5, scoring='accuracy',\n",
    "#     verbose=1, n_jobs=-1\n",
    "# )\n",
    "\n",
    "# TODO 3: Fit GridSearchCV\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# TODO 4: Report best parameters and score\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# TODO 5: Evaluate on test set\n",
    "# best_model = grid_search.best_estimator_\n",
    "# test_acc = accuracy_score(y_test, best_model.predict(X_test))\n",
    "# print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# TODO 6 (Bonus): Display results as a DataFrame\n",
    "# results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "# print(results_df[['param_n_estimators', 'param_max_depth', 'mean_test_score', 'std_test_score']]\n",
    "#       .sort_values('mean_test_score', ascending=False)\n",
    "#       .head(10)\n",
    "#       .to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 1. Parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None]\n",
    "}\n",
    "\n",
    "# 2. GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    rf, param_grid, cv=5, scoring='accuracy',\n",
    "    verbose=1, n_jobs=-1\n",
    ")\n",
    "\n",
    "# 3. Fit\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 4. Best results\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 5. Test evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "test_acc = accuracy_score(y_test, best_model.predict(X_test))\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# 6. Results table\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(\"\\nAll results (sorted by score):\")\n",
    "print(results_df[['param_n_estimators', 'param_max_depth', 'mean_test_score', 'std_test_score']]\n",
    "      .sort_values('mean_test_score', ascending=False)\n",
    "      .head(10)\n",
    "      .to_string(index=False))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4: Recursive Feature Elimination (RFE)\n",
    "\n",
    "**Goal:** Use RFE with `LogisticRegression` to select the top 5 features\n",
    "from a 15-feature dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. Generate a classification dataset with 15 features (8 informative).\n",
    "2. Apply `RFE` with `LogisticRegression` to select top 5 features.\n",
    "3. Print which features were selected and their rankings.\n",
    "4. Compare model accuracy with all features vs. selected features.\n",
    "5. Visualize feature rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 - Starter Code\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Generate dataset with 15 features, 8 informative\n",
    "X, y = make_classification(\n",
    "    n_samples=500, n_features=15, n_informative=8,\n",
    "    n_redundant=3, n_classes=2, random_state=42\n",
    ")\n",
    "feature_names = [f'feature_{i}' for i in range(15)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TODO 1: Create RFE with LogisticRegression, select top 5\n",
    "# estimator = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# rfe = RFE(estimator, n_features_to_select=5)\n",
    "# rfe.fit(X_train, y_train)\n",
    "\n",
    "# TODO 2: Print selected features and rankings\n",
    "# for name, selected, rank in zip(feature_names, rfe.support_, rfe.ranking_):\n",
    "#     status = 'SELECTED' if selected else f'rank {rank}'\n",
    "#     print(f\"{name}: {status}\")\n",
    "\n",
    "# TODO 3: Compare accuracy: all features vs selected features\n",
    "# all_scores = cross_val_score(\n",
    "#     LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     X_train, y_train, cv=5, scoring='accuracy'\n",
    "# )\n",
    "# rfe_scores = cross_val_score(\n",
    "#     LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     X_train[:, rfe.support_], y_train, cv=5, scoring='accuracy'\n",
    "# )\n",
    "# print(f\"\\nAll features ({X.shape[1]}): {all_scores.mean():.4f} +/- {all_scores.std():.4f}\")\n",
    "# print(f\"RFE features (5):   {rfe_scores.mean():.4f} +/- {rfe_scores.std():.4f}\")\n",
    "\n",
    "# TODO 4: Visualize rankings\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.barh(feature_names, rfe.ranking_)\n",
    "# plt.xlabel('RFE Ranking (1 = selected)')\n",
    "# plt.title('Feature Rankings by RFE')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=500, n_features=15, n_informative=8,\n",
    "    n_redundant=3, n_classes=2, random_state=42\n",
    ")\n",
    "feature_names = [f'feature_{i}' for i in range(15)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 1. RFE\n",
    "estimator = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rfe = RFE(estimator, n_features_to_select=5)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# 2. Print features\n",
    "print(\"Feature Selection Results:\")\n",
    "for name, selected, rank in zip(feature_names, rfe.support_, rfe.ranking_):\n",
    "    status = 'SELECTED' if selected else f'rank {rank}'\n",
    "    print(f\"  {name}: {status}\")\n",
    "\n",
    "selected_features = [name for name, sel in zip(feature_names, rfe.support_) if sel]\n",
    "print(f\"\\nSelected features: {selected_features}\")\n",
    "\n",
    "# 3. Compare accuracy\n",
    "all_scores = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    X_train, y_train, cv=5, scoring='accuracy'\n",
    ")\n",
    "rfe_scores = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    X_train[:, rfe.support_], y_train, cv=5, scoring='accuracy'\n",
    ")\n",
    "print(f\"\\nAll features ({X.shape[1]}): {all_scores.mean():.4f} +/- {all_scores.std():.4f}\")\n",
    "print(f\"RFE features (5):   {rfe_scores.mean():.4f} +/- {rfe_scores.std():.4f}\")\n",
    "\n",
    "# 4. Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = ['green' if s else 'gray' for s in rfe.support_]\n",
    "plt.barh(feature_names, rfe.ranking_, color=colors)\n",
    "plt.xlabel('RFE Ranking (1 = selected)')\n",
    "plt.title('Feature Rankings by RFE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5: End-to-End Mini-Project\n",
    "\n",
    "**Goal:** Complete an end-to-end ML workflow: load data, explore, split, create\n",
    "a baseline, build a pipeline, evaluate with cross-validation, and save the model.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the diabetes dataset and explore it briefly.\n",
    "2. Split into train/test (80/20).\n",
    "3. Create a baseline model (predict the mean of y_train).\n",
    "4. Build a pipeline: StandardScaler + Ridge regression.\n",
    "5. Evaluate with 5-fold CV, report R2, compare to baseline, and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 - Starter Code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# ---- STEP 1: Load and Explore ----\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "df = diabetes.frame\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDescription:\")\n",
    "print(df.describe())\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# TODO 2: Split 80/20\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "# print(f\"\\nTrain size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# TODO 3: Baseline model (predict the mean)\n",
    "# y_baseline = np.full_like(y_test, y_train.mean())\n",
    "# baseline_mse = mean_squared_error(y_test, y_baseline)\n",
    "# baseline_r2 = r2_score(y_test, y_baseline)\n",
    "# print(f\"\\nBaseline (predict mean):\")\n",
    "# print(f\"  MSE: {baseline_mse:.2f}\")\n",
    "# print(f\"  R2:  {baseline_r2:.4f}\")\n",
    "\n",
    "# TODO 4: Build pipeline (StandardScaler + Ridge)\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('ridge', Ridge(alpha=1.0))\n",
    "# ])\n",
    "\n",
    "# TODO 5a: Cross-validation\n",
    "# cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "# print(f\"\\nPipeline (5-fold CV):\")\n",
    "# print(f\"  R2: {cv_scores.mean():.4f} +/- {cv_scores.std():.4f}\")\n",
    "\n",
    "# TODO 5b: Fit on full training set and evaluate on test\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# test_mse = mean_squared_error(y_test, y_pred)\n",
    "# test_r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"\\nTest set evaluation:\")\n",
    "# print(f\"  MSE: {test_mse:.2f}\")\n",
    "# print(f\"  R2:  {test_r2:.4f}\")\n",
    "# print(f\"  Improvement over baseline: {test_r2 - baseline_r2:.4f} R2\")\n",
    "\n",
    "# TODO 5c: Save the model\n",
    "# joblib.dump(pipeline, 'diabetes_ridge_pipeline.pkl')\n",
    "# print(\"\\nModel saved to diabetes_ridge_pipeline.pkl\")\n",
    "\n",
    "# TODO 5d: Verify saved model\n",
    "# loaded_model = joblib.load('diabetes_ridge_pipeline.pkl')\n",
    "# verify_r2 = r2_score(y_test, loaded_model.predict(X_test))\n",
    "# print(f\"Loaded model R2: {verify_r2:.4f} (should match {test_r2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "<details><summary>Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# 1. Load and explore\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "df = diabetes.frame\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# 2. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"\\nTrain size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# 3. Baseline\n",
    "y_baseline = np.full_like(y_test, y_train.mean())\n",
    "baseline_mse = mean_squared_error(y_test, y_baseline)\n",
    "baseline_r2 = r2_score(y_test, y_baseline)\n",
    "print(f\"\\nBaseline (predict mean):\")\n",
    "print(f\"  MSE: {baseline_mse:.2f}\")\n",
    "print(f\"  R2:  {baseline_r2:.4f}\")\n",
    "\n",
    "# 4. Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "# 5a. Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"\\nPipeline (5-fold CV):\")\n",
    "print(f\"  R2: {cv_scores.mean():.4f} +/- {cv_scores.std():.4f}\")\n",
    "\n",
    "# 5b. Test evaluation\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nTest set evaluation:\")\n",
    "print(f\"  MSE: {test_mse:.2f}\")\n",
    "print(f\"  R2:  {test_r2:.4f}\")\n",
    "print(f\"  Improvement over baseline: {test_r2 - baseline_r2:.4f} R2\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title(f'Diabetes Prediction (R2={test_r2:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5c. Save\n",
    "joblib.dump(pipeline, 'diabetes_ridge_pipeline.pkl')\n",
    "print(\"\\nModel saved to diabetes_ridge_pipeline.pkl\")\n",
    "\n",
    "# 5d. Verify\n",
    "loaded_model = joblib.load('diabetes_ridge_pipeline.pkl')\n",
    "verify_r2 = r2_score(y_test, loaded_model.predict(X_test))\n",
    "print(f\"Loaded model R2: {verify_r2:.4f} (should match {test_r2:.4f})\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}