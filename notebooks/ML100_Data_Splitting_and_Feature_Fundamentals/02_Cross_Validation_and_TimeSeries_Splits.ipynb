{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Cross-Validation and Time-Series Splits\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- Explain why **cross-validation** gives a more reliable performance estimate than a single train/test split\n",
    "- Implement **KFold** and **StratifiedKFold** with scikit-learn\n",
    "- Use `cross_val_score` and `cross_validate` for quick evaluation\n",
    "- Apply **GroupKFold** to user/group-level data\n",
    "- Use **TimeSeriesSplit** and understand walk-forward validation\n",
    "- Visualize cross-validation folds\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed **Notebook 01** (train/test/validation splits)\n",
    "- Basic understanding of model fitting and scoring\n",
    "- Familiarity with NumPy, Pandas, and Matplotlib\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Why Cross-Validation?](#1-why-cross-validation)\n",
    "2. [KFold Cross-Validation](#2-kfold-cross-validation)\n",
    "3. [StratifiedKFold](#3-stratifiedkfold)\n",
    "4. [cross_val_score and cross_validate](#4-cross_val_score-and-cross_validate)\n",
    "5. [GroupKFold for User-Level Data](#5-groupkfold-for-user-level-data)\n",
    "6. [TimeSeriesSplit](#6-timeseriessplit)\n",
    "7. [Walk-Forward Validation](#7-walk-forward-validation)\n",
    "8. [Single Split vs. 5-Fold CV Comparison](#8-single-split-vs-5-fold-cv-comparison)\n",
    "9. [Common Mistakes](#9-common-mistakes)\n",
    "10. [Exercise](#10-exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Why Cross-Validation?\n",
    "\n",
    "A single train/test split suffers from **high variance**: the performance estimate depends heavily on *which* samples land in each set.\n",
    "\n",
    "**$k$-Fold Cross-Validation** addresses this by:\n",
    "\n",
    "1. Dividing the data into $k$ equally-sized folds\n",
    "2. Training on $k-1$ folds and testing on the remaining fold\n",
    "3. Repeating $k$ times so every sample serves as test exactly once\n",
    "4. Averaging the $k$ scores\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{i=1}^{k} L_i\n",
    "$$\n",
    "\n",
    "**Bias-Variance trade-off of $k$**:\n",
    "\n",
    "| $k$ | Bias | Variance | Cost |\n",
    "|-----|------|----------|------|\n",
    "| Small (e.g., 2) | Higher (less training data per fold) | Lower | Cheaper |\n",
    "| Large (e.g., $n$, LOOCV) | Lower (nearly all data for training) | Higher | Expensive |\n",
    "| Typical (5 or 10) | Good balance | Good balance | Moderate |\n",
    "\n",
    "In practice, **$k = 5$ or $k = 10$** is the standard choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    TimeSeriesSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Synthetic dataset (reused throughout)\n",
    "X, y = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.7, 0.3],\n",
    "    random_state=42,\n",
    ")\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. KFold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(\n",
    "        f\"Fold {fold}: \"\n",
    "        f\"train size = {len(train_idx)}, \"\n",
    "        f\"test size = {len(test_idx)}, \"\n",
    "        f\"test class dist = {np.bincount(y[test_idx])}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that plain `KFold` does **not** guarantee the same class ratio in each fold -- the class distribution can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. StratifiedKFold\n",
    "\n",
    "`StratifiedKFold` preserves the percentage of samples for each class in every fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    class_pct = np.bincount(y[test_idx]) / len(test_idx) * 100\n",
    "    print(\n",
    "        f\"Fold {fold}: \"\n",
    "        f\"test size = {len(test_idx)}, \"\n",
    "        f\"class % = [{class_pct[0]:.1f}, {class_pct[1]:.1f}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each fold now has roughly the same 70/30 split -- much better for imbalanced problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_folds(cv, X, y, groups=None, title=\"Cross-Validation Folds\"):\n",
    "    \"\"\"Visualize which indices are train vs. test in each fold.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    n_samples = len(y)\n",
    "\n",
    "    split_args = (X, y, groups) if groups is not None else (X, y)\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(*split_args)):\n",
    "        indices = np.zeros(n_samples)\n",
    "        indices[test_idx] = 1\n",
    "        ax.scatter(\n",
    "            range(n_samples), [fold] * n_samples,\n",
    "            c=indices, cmap=\"coolwarm\", marker=\"|\", s=30, linewidths=0.8\n",
    "        )\n",
    "\n",
    "    ax.set_yticks(range(cv.get_n_splits()))\n",
    "    ax.set_yticklabels([f\"Fold {i}\" for i in range(cv.get_n_splits())])\n",
    "    ax.set_xlabel(\"Sample index\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend(\n",
    "        handles=[Patch(color=\"#3B4CC0\", label=\"Train\"), Patch(color=\"#B40426\", label=\"Test\")],\n",
    "        loc=\"upper right\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cv_folds(skf, X, y, title=\"StratifiedKFold (5 folds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. `cross_val_score` and `cross_validate`\n",
    "\n",
    "These convenience functions automate the fit-predict-score loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# cross_val_score: returns an array of scores (one per fold)\n",
    "scores = cross_val_score(\n",
    "    model, X, y,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "print(f\"Fold scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate: returns a dict with fit_time, score_time, and test scores\n",
    "# Can also return train scores and multiple metrics\n",
    "cv_results = cross_validate(\n",
    "    model, X, y,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=[\"accuracy\", \"f1\", \"roc_auc\"],\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "results_df = pd.DataFrame(cv_results)\n",
    "print(results_df.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. GroupKFold for User-Level Data\n",
    "\n",
    "When samples are grouped (e.g., by user or patient), regular `KFold` can leak information. `GroupKFold` keeps all samples from a group in the same fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate: 50 users, variable number of samples per user\n",
    "rng = np.random.RandomState(42)\n",
    "n_users = 50\n",
    "samples_per_user = rng.randint(5, 15, size=n_users)\n",
    "groups = np.repeat(np.arange(n_users), samples_per_user)\n",
    "n_total = len(groups)\n",
    "\n",
    "X_grp = rng.randn(n_total, 8)\n",
    "y_grp = rng.randint(0, 2, n_total)\n",
    "\n",
    "print(f\"Total samples: {n_total}, Total groups: {n_users}\")\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "for fold, (tr_idx, te_idx) in enumerate(gkf.split(X_grp, y_grp, groups)):\n",
    "    tr_groups = set(groups[tr_idx])\n",
    "    te_groups = set(groups[te_idx])\n",
    "    print(\n",
    "        f\"Fold {fold}: train={len(tr_idx)} samples ({len(tr_groups)} groups), \"\n",
    "        f\"test={len(te_idx)} samples ({len(te_groups)} groups), \"\n",
    "        f\"overlap={tr_groups & te_groups}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. TimeSeriesSplit\n",
    "\n",
    "For time-ordered data, **future data must never appear in the training set**. `TimeSeriesSplit` implements an **expanding-window** strategy:\n",
    "\n",
    "- Fold 0: train on `[0, ..., k]`, test on `[k+1, ..., 2k]`\n",
    "- Fold 1: train on `[0, ..., 2k]`, test on `[2k+1, ..., 3k]`\n",
    "- ...and so on\n",
    "\n",
    "The training set grows with each fold, and the test set is always in the \"future\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated time series: 120 monthly observations\n",
    "n_ts = 120\n",
    "time_index = pd.date_range(\"2015-01-01\", periods=n_ts, freq=\"MS\")\n",
    "X_ts = np.arange(n_ts).reshape(-1, 1)  # simple feature: time step\n",
    "y_ts = np.sin(np.arange(n_ts) * 0.1) + rng.randn(n_ts) * 0.3\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_ts)):\n",
    "    print(\n",
    "        f\"Fold {fold}: train [{train_idx[0]}..{train_idx[-1]}] ({len(train_idx)} pts), \"\n",
    "        f\"test [{test_idx[0]}..{test_idx[-1]}] ({len(test_idx)} pts)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TimeSeriesSplit\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "cmap_train = \"#2196F3\"\n",
    "cmap_test = \"#F44336\"\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_ts)):\n",
    "    ax.barh(fold, len(train_idx), left=train_idx[0], height=0.6, color=cmap_train, edgecolor=\"white\")\n",
    "    ax.barh(fold, len(test_idx), left=test_idx[0], height=0.6, color=cmap_test, edgecolor=\"white\")\n",
    "\n",
    "ax.set_yticks(range(5))\n",
    "ax.set_yticklabels([f\"Fold {i}\" for i in range(5)])\n",
    "ax.set_xlabel(\"Sample index (time order)\")\n",
    "ax.set_title(\"TimeSeriesSplit -- Train (blue) vs. Test (red)\")\n",
    "ax.legend(\n",
    "    handles=[Patch(color=cmap_train, label=\"Train\"), Patch(color=cmap_test, label=\"Test\")],\n",
    "    loc=\"upper left\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Walk-Forward Validation\n",
    "\n",
    "Walk-forward validation extends `TimeSeriesSplit` with a **fixed-size sliding window** for training, rather than an ever-growing window. This is useful when:\n",
    "\n",
    "- Older data becomes less relevant (concept drift)\n",
    "- Training cost scales with dataset size\n",
    "\n",
    "```\n",
    "Fold 0:  [===TRAIN===][=TEST=]...........................\n",
    "Fold 1:  ...[===TRAIN===][=TEST=].......................\n",
    "Fold 2:  ......[===TRAIN===][=TEST=]...................\n",
    "```\n",
    "\n",
    "scikit-learn's `TimeSeriesSplit` supports this via `max_train_size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv_wf = TimeSeriesSplit(n_splits=5, max_train_size=30)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv_wf.split(X_ts)):\n",
    "    print(\n",
    "        f\"Fold {fold}: train [{train_idx[0]}..{train_idx[-1]}] (size {len(train_idx)}), \"\n",
    "        f\"test [{test_idx[0]}..{test_idx[-1]}] (size {len(test_idx)})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the training window is always capped at 30 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Single Split vs. 5-Fold CV Comparison\n",
    "\n",
    "Let's empirically compare the **stability** of a single random split vs. 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "n_experiments = 20\n",
    "single_split_scores_lr = []\n",
    "single_split_scores_dt = []\n",
    "\n",
    "for seed in range(n_experiments):\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=seed, stratify=y\n",
    "    )\n",
    "    # Logistic Regression\n",
    "    model_lr.fit(X_tr, y_tr)\n",
    "    single_split_scores_lr.append(model_lr.score(X_te, y_te))\n",
    "    # Decision Tree\n",
    "    model_dt.fit(X_tr, y_tr)\n",
    "    single_split_scores_dt.append(model_dt.score(X_te, y_te))\n",
    "\n",
    "# 5-fold CV scores\n",
    "cv5_scores_lr = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000, random_state=42), X, y,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    ")\n",
    "cv5_scores_dt = cross_val_score(\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42), X, y,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    ")\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(f\"  Single splits (20 runs): mean={np.mean(single_split_scores_lr):.4f}, std={np.std(single_split_scores_lr):.4f}\")\n",
    "print(f\"  5-Fold CV:               mean={cv5_scores_lr.mean():.4f}, std={cv5_scores_lr.std():.4f}\")\n",
    "\n",
    "print(\"\\n=== Decision Tree ===\")\n",
    "print(f\"  Single splits (20 runs): mean={np.mean(single_split_scores_dt):.4f}, std={np.std(single_split_scores_dt):.4f}\")\n",
    "print(f\"  5-Fold CV:               mean={cv5_scores_dt.mean():.4f}, std={cv5_scores_dt.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4), sharey=True)\n",
    "\n",
    "# Logistic Regression\n",
    "axes[0].hist(single_split_scores_lr, bins=10, alpha=0.6, color=\"#2196F3\", label=\"Single splits\")\n",
    "axes[0].axvline(cv5_scores_lr.mean(), color=\"#F44336\", linestyle=\"--\", linewidth=2, label=f\"5-fold CV mean ({cv5_scores_lr.mean():.3f})\")\n",
    "axes[0].set_xlabel(\"Accuracy\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Logistic Regression\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Decision Tree\n",
    "axes[1].hist(single_split_scores_dt, bins=10, alpha=0.6, color=\"#FF9800\", label=\"Single splits\")\n",
    "axes[1].axvline(cv5_scores_dt.mean(), color=\"#F44336\", linestyle=\"--\", linewidth=2, label=f\"5-fold CV mean ({cv5_scores_dt.mean():.3f})\")\n",
    "axes[1].set_xlabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Decision Tree\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle(\"Single Split Variability vs. 5-Fold CV\", fontweight=\"bold\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows how much a single split estimate can vary. The 5-fold CV mean (red dashed line) provides a more stable estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Common Mistakes\n",
    "\n",
    "| Mistake | Why it is harmful | Fix |\n",
    "|---------|-------------------|-----|\n",
    "| **Using regular KFold on time-series data** | Future data leaks into training, inflating scores | Use `TimeSeriesSplit` |\n",
    "| **Leaking validation into training** | Preprocessing (e.g., scaling) fitted on all data before CV, or performing feature selection using all data | Use `Pipeline` so preprocessing is done inside each CV fold |\n",
    "| **Ignoring group structure** | Same user/patient in both train and test folds | Use `GroupKFold` |\n",
    "| **Not shuffling KFold** | If data is sorted by class, folds will be pure and scores misleading | Set `shuffle=True` (but **not** for time series) |\n",
    "| **Reporting training scores as performance** | Overfitting goes undetected | Always report *test fold* scores from CV |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Exercise\n",
    "\n",
    "**Task**: Using the synthetic dataset `(X, y)` defined at the top of this notebook:\n",
    "\n",
    "1. Run **10-fold StratifiedKFold** cross-validation with a `DecisionTreeClassifier(max_depth=3, random_state=42)`.\n",
    "2. Report the **mean accuracy** and **standard deviation** across folds.\n",
    "3. Compare the result to the 5-fold result above -- is 10-fold more stable (lower std)?\n",
    "\n",
    "*Hint*: Use `cross_val_score` with `cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# ----------------------------------------------------------------\n",
    "# scores_10fold = cross_val_score(...)\n",
    "# print(f\"10-Fold CV: mean={...:.4f}, std={...:.4f}\")\n",
    "# ----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}