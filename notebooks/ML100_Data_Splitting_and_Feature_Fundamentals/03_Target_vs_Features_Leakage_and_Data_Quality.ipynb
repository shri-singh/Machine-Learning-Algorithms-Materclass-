{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Target vs. Features, Leakage, and Data Quality\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- Define **feature**, **target**, **label**, **predictor**, and **response variable**\n",
    "- Explain what **data leakage** is and identify its two main types\n",
    "- Demonstrate the effect of leakage on model performance with code\n",
    "- Apply correct preprocessing patterns (fit on train, transform on test)\n",
    "- Identify common **data quality** issues: missing values, duplicates, inconsistent types\n",
    "- Understand the concept of **generalization**\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed **Notebook 01** (train/test splits) and **Notebook 02** (cross-validation)\n",
    "- Basic NumPy, Pandas, and scikit-learn usage\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Terminology: Features, Targets, and Friends](#1-terminology-features-targets-and-friends)\n",
    "2. [What Is Data Leakage?](#2-what-is-data-leakage)\n",
    "3. [Leakage Demo: Scaling Before vs. After Split](#3-leakage-demo-scaling-before-vs-after-split)\n",
    "4. [More Leakage Examples](#4-more-leakage-examples)\n",
    "5. [Generalization: The Big Picture](#5-generalization-the-big-picture)\n",
    "6. [Data Quality Essentials](#6-data-quality-essentials)\n",
    "7. [Common Mistakes](#7-common-mistakes)\n",
    "8. [Exercise](#8-exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Terminology: Features, Targets, and Friends\n",
    "\n",
    "Machine learning literature uses many names for the same concepts. Here is a reference table:\n",
    "\n",
    "| ML Term | Statistics Term | scikit-learn Convention | Description |\n",
    "|---------|----------------|------------------------|-------------|\n",
    "| **Feature** | Predictor / Independent variable / Covariate | `X` (capital) | Input columns the model uses to make predictions |\n",
    "| **Target** | Response / Dependent variable / Outcome | `y` (lowercase) | The value we want to predict |\n",
    "| **Label** | (same as target in classification) | `y` | Categorical target in classification tasks |\n",
    "| **Sample** | Observation / Data point | One row of `X` | A single example |\n",
    "\n",
    "In a supervised learning setting:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(X) + \\epsilon\n",
    "$$\n",
    "\n",
    "- $X \\in \\mathbb{R}^{n \\times p}$ -- feature matrix ($n$ samples, $p$ features)\n",
    "- $y \\in \\mathbb{R}^{n}$ -- target vector\n",
    "- $f$ -- the function we are trying to learn\n",
    "- $\\epsilon$ -- irreducible noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a synthetic dataset we will use throughout\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=8,\n",
    "    n_redundant=4,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "df[\"target\"] = y\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly separate features (X) from target (y)\n",
    "feature_cols = [c for c in df.columns if c != \"target\"]\n",
    "X = df[feature_cols].values\n",
    "y = df[\"target\"].values\n",
    "\n",
    "print(f\"Features (X): {X.shape}  -- {len(feature_cols)} predictors\")\n",
    "print(f\"Target   (y): {y.shape}  -- binary classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. What Is Data Leakage?\n",
    "\n",
    "**Data leakage** occurs when information from outside the training set is used to create the model. This leads to **overly optimistic** performance estimates that do not hold up in production.\n",
    "\n",
    "### Two main types\n",
    "\n",
    "| Type | Description | Example |\n",
    "|------|-------------|---------|\n",
    "| **Target leakage** | A feature contains information that is derived from or strongly correlated with the target *and would not be available at prediction time* | Using \"treatment outcome\" to predict \"disease diagnosis\" |\n",
    "| **Train-test contamination** | Information from the test set leaks into the training process | Fitting a scaler on the full dataset, then splitting |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Leakage Demo: Scaling Before vs. After Split\n",
    "\n",
    "This is the most common form of train-test contamination. Let's measure the impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. WRONG: Scale all data, then split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- WRONG approach: scale everything first ----\n",
    "scaler_wrong = StandardScaler()\n",
    "X_scaled_all = scaler_wrong.fit_transform(X)  # fit on ALL data (leakage!)\n",
    "\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
    "    X_scaled_all, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model_wrong = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_wrong.fit(X_train_w, y_train_w)\n",
    "score_wrong = model_wrong.score(X_test_w, y_test_w)\n",
    "\n",
    "print(f\"WRONG (scale-then-split) test accuracy: {score_wrong:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. CORRECT: Split first, then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CORRECT approach: split first, then fit scaler on train only ----\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler_correct = StandardScaler()\n",
    "X_train_c_scaled = scaler_correct.fit_transform(X_train_c)  # fit on TRAIN only\n",
    "X_test_c_scaled = scaler_correct.transform(X_test_c)        # transform test\n",
    "\n",
    "model_correct = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_correct.fit(X_train_c_scaled, y_train_c)\n",
    "score_correct = model_correct.score(X_test_c_scaled, y_test_c)\n",
    "\n",
    "print(f\"CORRECT (split-then-scale) test accuracy: {score_correct:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDifference: {abs(score_wrong - score_correct):.4f}\")\n",
    "print(\n",
    "    \"On this clean synthetic dataset the difference is small, but on real-world\\n\"\n",
    "    \"data with noisy, high-dimensional features the gap can be substantial.\\n\"\n",
    "    \"The WRONG approach is always theoretically invalid regardless of the gap size.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Best practice: use a Pipeline\n",
    "\n",
    "A `Pipeline` guarantees that preprocessing is fitted **only** on training data during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, random_state=42)),\n",
    "])\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    pipe, X, y,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "print(f\"Pipeline + 5-fold CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "print(\"The Pipeline ensures fit_transform runs ONLY on training folds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. More Leakage Examples\n",
    "\n",
    "### 4a. Using future data (time-based leakage)\n",
    "\n",
    "If you are predicting stock prices tomorrow, you cannot use tomorrow's trading volume as a feature. This seems obvious, but in practice it happens when:\n",
    "\n",
    "- A database join brings in records timestamped after the prediction date\n",
    "- Aggregated features (e.g., \"average rating for this product\") include future reviews\n",
    "\n",
    "### 4b. Proxy variables (target leakage)\n",
    "\n",
    "A feature that is a **direct consequence** of the target:\n",
    "\n",
    "- Predicting \"will the patient be readmitted?\" using \"number of follow-up appointments\" -- follow-ups happen *because* the patient was readmitted\n",
    "- Predicting \"will the customer churn?\" using \"cancellation_reason\" -- that column is only populated *after* the customer churns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate target leakage with a proxy variable\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Suppose target = 1 means \"churned\"\n",
    "n = 500\n",
    "legit_feature = rng.randn(n)\n",
    "target = (legit_feature + rng.randn(n) * 0.5 > 0.3).astype(int)\n",
    "\n",
    "# A leaky feature: \"days_since_cancellation\" -- only known AFTER churn\n",
    "leaky_feature = np.where(target == 1, rng.randint(1, 30, n), 0)\n",
    "\n",
    "# Build a DataFrame\n",
    "df_leak = pd.DataFrame({\n",
    "    \"legit_feature\": legit_feature,\n",
    "    \"days_since_cancellation\": leaky_feature,\n",
    "    \"churned\": target,\n",
    "})\n",
    "\n",
    "# Model WITH the leaky feature\n",
    "X_leak = df_leak[[\"legit_feature\", \"days_since_cancellation\"]].values\n",
    "y_leak = df_leak[\"churned\"].values\n",
    "\n",
    "scores_leak = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    X_leak, y_leak,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    ")\n",
    "\n",
    "# Model WITHOUT the leaky feature\n",
    "X_clean = df_leak[[\"legit_feature\"]].values\n",
    "\n",
    "scores_clean = cross_val_score(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    X_clean, y_leak,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    ")\n",
    "\n",
    "print(f\"With leaky feature:    accuracy = {scores_leak.mean():.4f}\")\n",
    "print(f\"Without leaky feature: accuracy = {scores_clean.mean():.4f}\")\n",
    "print(f\"\\nThe leaky feature inflates accuracy by {scores_leak.mean() - scores_clean.mean():.4f}\")\n",
    "print(\"This performance would NOT hold in production where the feature is unavailable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Generalization: The Big Picture\n",
    "\n",
    "Everything in this module series connects to one central idea: **generalization** -- the model's ability to perform well on data it has never seen.\n",
    "\n",
    "```\n",
    "+---------------------------------------------------------------------------+\n",
    "|                        ALL AVAILABLE DATA                                 |\n",
    "|                                                                           |\n",
    "|   +---------------------------+  +-------------+  +-------------------+   |\n",
    "|   |      TRAINING SET         |  |  VALIDATION  |  |     TEST SET      |   |\n",
    "|   |                           |  |     SET      |  |                   |   |\n",
    "|   |  - Learn patterns         |  |  - Tune      |  |  - Final, honest  |   |\n",
    "|   |  - Fit model parameters   |  |    hyper-    |  |    performance    |   |\n",
    "|   |  - Fit preprocessors      |  |    params    |  |    estimate       |   |\n",
    "|   |                           |  |  - Model     |  |  - Touch ONCE     |   |\n",
    "|   |                           |  |    selection |  |                   |   |\n",
    "|   +---------------------------+  +-------------+  +-------------------+   |\n",
    "|                                                                           |\n",
    "|   Generalization gap = Test performance - Training performance            |\n",
    "|   Large gap => overfitting                                                |\n",
    "|   Both low  => underfitting                                               |\n",
    "+---------------------------------------------------------------------------+\n",
    "```\n",
    "\n",
    "**Key principles**:\n",
    "\n",
    "- Split data *before* any preprocessing or feature engineering\n",
    "- Never use test data for any decision (model selection, hyperparameter tuning, feature selection)\n",
    "- Use cross-validation for a more robust estimate of generalization\n",
    "- Watch for data leakage -- it creates an illusion of good generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Data Quality Essentials\n",
    "\n",
    "Before modeling, always audit the raw data for quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"messy\" DataFrame to illustrate common issues\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "df_messy = pd.DataFrame({\n",
    "    \"age\": [25, 30, np.nan, 45, 30, 25, 52, np.nan, 38, 30],\n",
    "    \"income\": [50000, 60000, 45000, 80000, 60000, 50000, 95000, 72000, 68000, 60000],\n",
    "    \"city\": [\"NYC\", \"LA\", \"NYC\", \"Chicago\", \"LA\", \"NYC\", \"LA\", \"Chicago\", \"nyc\", \"la\"],\n",
    "    \"signup_date\": [\n",
    "        \"2023-01-15\", \"2023-02-20\", \"2023-03-10\", \"2023/04/05\", \"2023-02-20\",\n",
    "        \"2023-01-15\", \"2023-06-01\", \"2023-07-12\", \"2023-08-25\", \"2023-02-20\",\n",
    "    ],\n",
    "    \"purchased\": [1, 0, 1, 1, 0, 1, 0, 1, 0, 0],\n",
    "})\n",
    "\n",
    "print(\"Raw data:\")\n",
    "df_messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values per column:\")\n",
    "print(df_messy.isnull().sum())\n",
    "print(f\"\\nTotal missing: {df_messy.isnull().sum().sum()} out of {df_messy.size} cells \"\n",
    "      f\"({df_messy.isnull().sum().sum() / df_messy.size * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common strategies** for missing values (covered in depth in later modules):\n",
    "\n",
    "- **Drop rows** -- simple but loses data\n",
    "- **Impute** with mean/median/mode\n",
    "- **Impute** with a model (e.g., KNN imputer)\n",
    "- **Flag** missingness as a feature itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dupes = df_messy.duplicated().sum()\n",
    "print(f\"Duplicate rows: {n_dupes}\")\n",
    "print(\"\\nDuplicated rows:\")\n",
    "df_messy[df_messy.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates can:\n",
    "\n",
    "- **Bias** the model towards repeated patterns\n",
    "- Cause **leakage** if the same row appears in both train and test sets\n",
    "- Inflate metrics artificially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Inconsistent types and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City names: inconsistent casing\n",
    "print(\"Unique city values (raw):\", df_messy[\"city\"].unique())\n",
    "\n",
    "# Fix: normalize to lowercase\n",
    "df_clean = df_messy.copy()\n",
    "df_clean[\"city\"] = df_clean[\"city\"].str.lower()\n",
    "print(\"Unique city values (cleaned):\", df_clean[\"city\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date formats: mixed separators\n",
    "print(\"Raw dates:\")\n",
    "print(df_messy[\"signup_date\"].values)\n",
    "\n",
    "# Fix: parse to datetime\n",
    "df_clean[\"signup_date\"] = pd.to_datetime(df_clean[\"signup_date\"])\n",
    "print(\"\\nParsed dates:\")\n",
    "print(df_clean[\"signup_date\"].values)\n",
    "print(f\"dtype: {df_clean['signup_date'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality checklist\n",
    "\n",
    "Before any modeling, run through this quick audit:\n",
    "\n",
    "1. `df.info()` -- check dtypes and non-null counts\n",
    "2. `df.isnull().sum()` -- missing values\n",
    "3. `df.duplicated().sum()` -- duplicate rows\n",
    "4. `df.describe()` -- check ranges, means, and outliers\n",
    "5. For categorical columns: `df[col].value_counts()` -- check for inconsistent labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Common Mistakes\n",
    "\n",
    "| Mistake | Why it is harmful | Fix |\n",
    "|---------|-------------------|-----|\n",
    "| **Fitting preprocessor on full dataset** | Test set statistics leak into training; inflates performance | Use `Pipeline` or manually `fit` on train, `transform` on test |\n",
    "| **Feature derived from target** | Model sees the answer directly or via a strong proxy | Audit features: ask \"would I have this at prediction time?\" |\n",
    "| **Using future data as features** | Temporal leakage -- model gets information from the future | Ensure all features are available *before* the prediction timestamp |\n",
    "| **Ignoring duplicates across splits** | Same sample in train and test leads to overoptimistic scores | Deduplicate before splitting |\n",
    "| **Not checking data types** | Strings encoded as numbers (e.g., zip codes) get treated as continuous | Always run `df.info()` and `df.describe()` first |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Exercise\n",
    "\n",
    "**Task**: You are given the following DataFrame. Identify and fix the leakage problem, then compare model performance before and after the fix.\n",
    "\n",
    "1. Create the DataFrame below.\n",
    "2. Train a `LogisticRegression` using 5-fold stratified CV **with all columns as features** (including the leaky one). Record accuracy.\n",
    "3. Remove the leaky feature and repeat. Record accuracy.\n",
    "4. Explain why the first accuracy is unrealistically high.\n",
    "\n",
    "```python\n",
    "rng = np.random.RandomState(42)\n",
    "n = 300\n",
    "hours_studied = rng.uniform(1, 10, n)\n",
    "passed = (hours_studied + rng.randn(n) * 1.5 > 5).astype(int)\n",
    "# Leaky feature: \"grade\" is assigned AFTER the exam\n",
    "grade = np.where(passed == 1, rng.uniform(70, 100, n), rng.uniform(20, 60, n))\n",
    "\n",
    "df_ex = pd.DataFrame({\n",
    "    \"hours_studied\": hours_studied,\n",
    "    \"grade\": grade,\n",
    "    \"passed\": passed,\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# ----------------------------------------------------------------\n",
    "# Step 1: Create df_ex as shown above\n",
    "# Step 2: CV with all features -> score_all\n",
    "# Step 3: CV without 'grade' -> score_no_leak\n",
    "# Step 4: Print and compare\n",
    "# ----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}