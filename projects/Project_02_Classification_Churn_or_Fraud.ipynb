{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 2: Customer Churn Prediction (Classification)\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this project you will be able to:\n",
    "\n",
    "- Frame a business problem as a binary classification task\n",
    "- Build preprocessing pipelines with `ColumnTransformer` for mixed feature types\n",
    "- Train and compare Logistic Regression, Random Forest, and Gradient Boosting classifiers\n",
    "- Evaluate models using confusion matrices, precision, recall, F1, ROC-AUC, and PR-AUC\n",
    "- Tune decision thresholds using a business-cost framework\n",
    "- Handle class imbalance with `class_weight`\n",
    "- Interpret feature importances for stakeholder communication\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Libraries: numpy, pandas, matplotlib, seaborn, scikit-learn, joblib\n",
    "- Familiarity with classification metrics and logistic regression\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Problem Statement & Business Context](#1)\n",
    "2. [Data Generation](#2)\n",
    "3. [Exploratory Data Analysis](#3)\n",
    "4. [Data Splitting](#4)\n",
    "5. [Baseline Model](#5)\n",
    "6. [Preprocessing Pipeline](#6)\n",
    "7. [Model Training](#7)\n",
    "8. [Evaluation & Comparison](#8)\n",
    "9. [Threshold Tuning](#9)\n",
    "10. [Handling Class Imbalance](#10)\n",
    "11. [Final Test Evaluation](#11)\n",
    "12. [Feature Importance](#12)\n",
    "13. [Model Saving](#13)\n",
    "14. [Conclusions](#14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Problem Statement & Business Context\n",
    "\n",
    "**Scenario:** A telecom company is experiencing a monthly churn rate of approximately 25%. Acquiring a new customer costs 5-7x more than retaining an existing one. The retention team wants a predictive model to identify at-risk customers so they can offer targeted incentives.\n",
    "\n",
    "**Business Cost Analysis:**\n",
    "- **False Negative (missed churner):** The customer leaves. Estimated cost: ~$500 (lost revenue + acquisition cost of replacement).\n",
    "- **False Positive (retention offer to non-churner):** Unnecessary discount or incentive. Estimated cost: ~$50.\n",
    "- The cost ratio (FN:FP) is roughly 10:1, which means **recall is more important than precision**, but we still want to avoid flooding loyal customers with unnecessary offers.\n",
    "\n",
    "**Goal:** Build a classifier that maximizes recall while keeping precision at an acceptable level, and choose an optimal decision threshold that minimizes total business cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Data Generation\n",
    "\n",
    "We generate a synthetic telecom churn dataset with 1000 customers, 10 features (mix of numeric and categorical), and a ~25% churn rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# --- Feature generation ---\n",
    "tenure_months = np.random.exponential(24, n).clip(1, 72).astype(int)\n",
    "monthly_charges = np.random.normal(65, 20, n).clip(20, 120).round(2)\n",
    "total_charges = (tenure_months * monthly_charges * np.random.uniform(0.85, 1.05, n)).round(2)\n",
    "contract_type = np.random.choice([\"Month-to-month\", \"One year\", \"Two year\"], n, p=[0.50, 0.30, 0.20])\n",
    "internet_service = np.random.choice([\"DSL\", \"Fiber optic\", \"No\"], n, p=[0.35, 0.45, 0.20])\n",
    "num_support_tickets = np.random.poisson(1.5, n)\n",
    "has_online_security = np.random.choice([0, 1], n, p=[0.55, 0.45])\n",
    "is_senior = np.random.choice([0, 1], n, p=[0.85, 0.15])\n",
    "num_dependents = np.random.choice([0, 1, 2, 3, 4], n, p=[0.40, 0.25, 0.20, 0.10, 0.05])\n",
    "payment_method = np.random.choice(\n",
    "    [\"Electronic check\", \"Mailed check\", \"Bank transfer\", \"Credit card\"],\n",
    "    n, p=[0.35, 0.20, 0.25, 0.20]\n",
    ")\n",
    "\n",
    "# --- Churn label (logistic formula for ~25% churn) ---\n",
    "churn_logit = (\n",
    "    -2.0\n",
    "    - 0.04 * tenure_months\n",
    "    + 0.02 * monthly_charges\n",
    "    + 1.2 * (contract_type == \"Month-to-month\").astype(float)\n",
    "    + 0.5 * (internet_service == \"Fiber optic\").astype(float)\n",
    "    + 0.3 * num_support_tickets\n",
    "    - 0.4 * has_online_security\n",
    "    + 0.3 * is_senior\n",
    "    - 0.2 * num_dependents\n",
    "    + 0.4 * (payment_method == \"Electronic check\").astype(float)\n",
    "    + np.random.normal(0, 0.5, n)  # noise\n",
    ")\n",
    "churn_prob = 1 / (1 + np.exp(-churn_logit))\n",
    "churned = (np.random.uniform(0, 1, n) < churn_prob).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"tenure_months\": tenure_months,\n",
    "    \"monthly_charges\": monthly_charges,\n",
    "    \"total_charges\": total_charges,\n",
    "    \"contract_type\": contract_type,\n",
    "    \"internet_service\": internet_service,\n",
    "    \"num_support_tickets\": num_support_tickets,\n",
    "    \"has_online_security\": has_online_security,\n",
    "    \"is_senior\": is_senior,\n",
    "    \"num_dependents\": num_dependents,\n",
    "    \"payment_method\": payment_method,\n",
    "    \"churned\": churned,\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Churn rate: {df['churned'].mean():.1%}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "df[\"churned\"].value_counts().plot(kind=\"bar\", ax=axes[0], color=[\"steelblue\", \"salmon\"], edgecolor=\"black\")\n",
    "axes[0].set_title(\"Churn Class Distribution\")\n",
    "axes[0].set_xticklabels([\"Stayed (0)\", \"Churned (1)\"], rotation=0)\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "df[\"churned\"].value_counts().plot(kind=\"pie\", ax=axes[1], autopct=\"%1.1f%%\",\n",
    "                                   colors=[\"steelblue\", \"salmon\"], labels=[\"Stayed\", \"Churned\"])\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].set_title(\"Churn Proportion\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric feature distributions by churn status\n",
    "numeric_features = [\"tenure_months\", \"monthly_charges\", \"total_charges\",\n",
    "                    \"num_support_tickets\", \"num_dependents\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(22, 4))\n",
    "for ax, col in zip(axes, numeric_features):\n",
    "    for label, color in [(0, \"steelblue\"), (1, \"salmon\")]:\n",
    "        subset = df[df[\"churned\"] == label][col]\n",
    "        ax.hist(subset, bins=25, alpha=0.6, color=color, label=f\"Churn={label}\", edgecolor=\"black\")\n",
    "    ax.set_title(col)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle(\"Numeric Feature Distributions by Churn Status\", fontsize=14, y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features vs churn\n",
    "cat_features = [\"contract_type\", \"internet_service\", \"payment_method\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for ax, col in zip(axes, cat_features):\n",
    "    churn_rates = df.groupby(col)[\"churned\"].mean().sort_values(ascending=False)\n",
    "    churn_rates.plot(kind=\"bar\", ax=ax, color=\"coral\", edgecolor=\"black\")\n",
    "    ax.set_title(f\"Churn Rate by {col}\")\n",
    "    ax.set_ylabel(\"Churn Rate\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (numeric features only)\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, square=True)\n",
    "plt.title(\"Correlation Matrix (Numeric Features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. Data Splitting\n",
    "\n",
    "We use stratified splitting to preserve the churn class ratio in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=[\"churned\"])\n",
    "y = df[\"churned\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples (churn rate: {y_train.mean():.1%})\")\n",
    "print(f\"Test set:     {X_test.shape[0]} samples (churn rate: {y_test.mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix,\n",
    "                             classification_report)\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "y_dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "print(\"Baseline (Most Frequent) Performance:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_dummy_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_dummy_pred, zero_division=0):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_dummy_pred, zero_division=0):.4f}\")\n",
    "print(f\"  F1:        {f1_score(y_test, y_dummy_pred, zero_division=0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. Preprocessing Pipeline\n",
    "\n",
    "We use `ColumnTransformer` to apply different transformations to numeric and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = [\"tenure_months\", \"monthly_charges\", \"total_charges\",\n",
    "                    \"num_support_tickets\", \"has_online_security\",\n",
    "                    \"is_senior\", \"num_dependents\"]\n",
    "categorical_features = [\"contract_type\", \"internet_service\", \"payment_method\"]\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Quick check\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "print(f\"Processed feature matrix shape: {X_train_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## 7. Model Training\n",
    "\n",
    "We train three models:\n",
    "1. **Logistic Regression** - interpretable, good baseline\n",
    "2. **Random Forest** - handles non-linear relationships\n",
    "3. **Gradient Boosting** - often top-performing for tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "    ]),\n",
    "    \"Gradient Boosting\": Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", GradientBoostingClassifier(n_estimators=200, random_state=42))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    trained_models[name] = pipe\n",
    "    print(f\"{name} trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "## 8. Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "results = []\n",
    "for name, pipe in trained_models.items():\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_prob),\n",
    "        \"PR-AUC\": average_precision_score(y_test, y_prob),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index(\"Model\").round(4)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, (name, pipe) in zip(axes, trained_models.items()):\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Stayed\", \"Churned\"], yticklabels=[\"Stayed\", \"Churned\"])\n",
    "    ax.set_title(f\"{name}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.suptitle(\"Confusion Matrices\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and PR curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for name, pipe in trained_models.items():\n",
    "    RocCurveDisplay.from_estimator(pipe, X_test, y_test, ax=axes[0], name=name)\n",
    "    PrecisionRecallDisplay.from_estimator(pipe, X_test, y_test, ax=axes[1], name=name)\n",
    "\n",
    "axes[0].set_title(\"ROC Curves\")\n",
    "axes[0].plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "axes[0].legend()\n",
    "axes[1].set_title(\"Precision-Recall Curves\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model by ROC-AUC\n",
    "best_model_name = results_df[\"ROC-AUC\"].idxmax()\n",
    "best_pipe = trained_models[best_model_name]\n",
    "print(f\"Best model: {best_model_name} (ROC-AUC = {results_df.loc[best_model_name, 'ROC-AUC']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "## 9. Threshold Tuning\n",
    "\n",
    "The default threshold of 0.5 may not be optimal given our asymmetric costs (FN cost >> FP cost). We search for the threshold that minimizes total business cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_best = best_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Business cost parameters\n",
    "cost_fn = 500   # cost of missing a churner\n",
    "cost_fp = 50    # cost of unnecessary retention offer\n",
    "\n",
    "thresholds = np.arange(0.05, 0.95, 0.01)\n",
    "costs = []\n",
    "f1_scores = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob_best >= t).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred_t)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    total_cost = fn * cost_fn + fp * cost_fp\n",
    "    costs.append(total_cost)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_t, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, y_pred_t, zero_division=0))\n",
    "    precisions.append(precision_score(y_test, y_pred_t, zero_division=0))\n",
    "\n",
    "optimal_idx = np.argmin(costs)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(thresholds, costs, color=\"red\", linewidth=2)\n",
    "axes[0].axvline(x=optimal_threshold, color=\"green\", linestyle=\"--\", label=f\"Optimal: {optimal_threshold:.2f}\")\n",
    "axes[0].axvline(x=0.5, color=\"gray\", linestyle=\":\", label=\"Default: 0.50\")\n",
    "axes[0].set_xlabel(\"Threshold\")\n",
    "axes[0].set_ylabel(\"Total Business Cost ($)\")\n",
    "axes[0].set_title(\"Business Cost vs Threshold\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(thresholds, precisions, label=\"Precision\", linewidth=2)\n",
    "axes[1].plot(thresholds, recalls, label=\"Recall\", linewidth=2)\n",
    "axes[1].plot(thresholds, f1_scores, label=\"F1\", linewidth=2)\n",
    "axes[1].axvline(x=optimal_threshold, color=\"green\", linestyle=\"--\", label=f\"Optimal: {optimal_threshold:.2f}\")\n",
    "axes[1].set_xlabel(\"Threshold\")\n",
    "axes[1].set_ylabel(\"Score\")\n",
    "axes[1].set_title(\"Metrics vs Threshold\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"At this threshold: Recall={recalls[optimal_idx]:.3f}, \"\n",
    "      f\"Precision={precisions[optimal_idx]:.3f}, F1={f1_scores[optimal_idx]:.3f}\")\n",
    "print(f\"Min cost: ${costs[optimal_idx]:,.0f} (vs ${costs[np.argmin(np.abs(thresholds - 0.5))]:,.0f} at default 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a>\n",
    "## 10. Handling Class Imbalance\n",
    "\n",
    "We retrain the best model with `class_weight='balanced'` to see if explicitly accounting for class imbalance improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a balanced version of the best model type\n",
    "balanced_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight=\"balanced\"),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
    "}\n",
    "\n",
    "# Get the model type from best_model_name\n",
    "if best_model_name == \"Gradient Boosting\":\n",
    "    # GradientBoosting does not support class_weight; use sample_weight instead\n",
    "    from sklearn.utils.class_weight import compute_sample_weight\n",
    "    balanced_pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", GradientBoostingClassifier(n_estimators=200, random_state=42))\n",
    "    ])\n",
    "    sample_weights = compute_sample_weight(\"balanced\", y_train)\n",
    "    balanced_pipe.fit(X_train, y_train, model__sample_weight=sample_weights)\n",
    "else:\n",
    "    balanced_pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", balanced_models[best_model_name])\n",
    "    ])\n",
    "    balanced_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_balanced = balanced_pipe.predict(X_test)\n",
    "y_prob_balanced = balanced_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Balanced {best_model_name} (default threshold 0.5):\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_pred_balanced):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_balanced):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_pred_balanced):.4f}\")\n",
    "print(f\"  F1:        {f1_score(y_test, y_pred_balanced):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_prob_balanced):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare confusion matrices: original vs balanced\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for ax, (title, y_p) in zip(axes, [(f\"{best_model_name} (Original)\", best_pipe.predict(X_test)),\n",
    "                                    (f\"{best_model_name} (Balanced)\", y_pred_balanced)]):\n",
    "    cm = confusion_matrix(y_test, y_p)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Stayed\", \"Churned\"], yticklabels=[\"Stayed\", \"Churned\"])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a>\n",
    "## 11. Final Test Evaluation\n",
    "\n",
    "We apply the optimal threshold from the cost analysis to the best model for our final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions using the optimal threshold\n",
    "y_final_prob = best_pipe.predict_proba(X_test)[:, 1]\n",
    "y_final_pred = (y_final_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(\"  FINAL MODEL - Test Set Performance\")\n",
    "print(f\"  Model: {best_model_name}\")\n",
    "print(f\"  Threshold: {optimal_threshold:.2f}\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_final_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_final_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_final_pred):.4f}\")\n",
    "print(f\"  F1:        {f1_score(y_test, y_final_pred):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_final_prob):.4f}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_final_pred, target_names=[\"Stayed\", \"Churned\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a>\n",
    "## 12. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "cat_encoder = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_feature_names = cat_encoder.get_feature_names_out(categorical_features).tolist()\n",
    "all_feature_names = numeric_features + cat_feature_names\n",
    "\n",
    "# Extract importances based on model type\n",
    "model_obj = best_pipe.named_steps[\"model\"]\n",
    "\n",
    "if hasattr(model_obj, \"feature_importances_\"):\n",
    "    importances = model_obj.feature_importances_\n",
    "    importance_label = \"Feature Importance (Gini)\"\n",
    "elif hasattr(model_obj, \"coef_\"):\n",
    "    importances = np.abs(model_obj.coef_[0])\n",
    "    importance_label = \"Absolute Coefficient\"\n",
    "else:\n",
    "    importances = np.zeros(len(all_feature_names))\n",
    "    importance_label = \"N/A\"\n",
    "\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"Feature\": all_feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(\"Importance\", ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feat_imp_df[\"Feature\"], feat_imp_df[\"Importance\"], color=\"steelblue\", edgecolor=\"black\")\n",
    "plt.xlabel(importance_label)\n",
    "plt.title(f\"Feature Importance ({best_model_name})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Features:\")\n",
    "print(feat_imp_df.sort_values(\"Importance\", ascending=False).head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a>\n",
    "## 13. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# Save model and optimal threshold together\n",
    "artifact = {\n",
    "    \"pipeline\": best_pipe,\n",
    "    \"optimal_threshold\": optimal_threshold,\n",
    "    \"model_name\": best_model_name,\n",
    "}\n",
    "\n",
    "model_path = \"saved_models/churn_model.joblib\"\n",
    "joblib.dump(artifact, model_path)\n",
    "print(f\"Model artifact saved to: {model_path}\")\n",
    "\n",
    "# Verify\n",
    "loaded = joblib.load(model_path)\n",
    "test_probs = loaded[\"pipeline\"].predict_proba(X_test[:5])[:, 1]\n",
    "test_preds = (test_probs >= loaded[\"optimal_threshold\"]).astype(int)\n",
    "print(f\"\\nSample predictions (threshold={loaded['optimal_threshold']:.2f}):\")\n",
    "print(f\"  Probabilities: {test_probs.round(3)}\")\n",
    "print(f\"  Predictions:   {test_preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"14\"></a>\n",
    "## 14. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Contract type** and **tenure** are the strongest predictors of churn. Month-to-month contracts and short tenure strongly increase churn risk.\n",
    "- **Electronic check** as a payment method is associated with higher churn, possibly due to lack of commitment.\n",
    "- The default 0.5 threshold is not optimal for this business problem. Lowering the threshold improves recall, catching more churners at a modest increase in false positives.\n",
    "- Balancing class weights increases recall but may decrease precision. The optimal trade-off depends on the actual business cost structure.\n",
    "\n",
    "### Business Recommendations\n",
    "\n",
    "1. **Target month-to-month customers** with 1-12 months tenure for proactive retention outreach.\n",
    "2. **Incentivize contract upgrades** from month-to-month to annual or two-year plans.\n",
    "3. **Monitor support ticket volume** as an early warning signal.\n",
    "4. **Deploy the model** with the business-cost-optimized threshold to maximize ROI on retention campaigns.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **A/B test** the model-driven retention offers vs. existing strategy.\n",
    "2. **Add time-series features** (recent usage trends, billing changes).\n",
    "3. **Try XGBoost/LightGBM** for potentially better performance.\n",
    "4. **Build a real-time scoring pipeline** for integration with CRM systems.\n",
    "5. **Implement model monitoring** to detect data drift and trigger retraining."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}